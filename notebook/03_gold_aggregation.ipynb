{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb9051d9-87cf-4521-bcd4-add4a0953c44",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Setup și Crearea View-ului de Bază"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, count, countDistinct, sum, avg, max, date_format, explode\n",
    "\n",
    "# --- 1. UNITY CATALOG CONFIGURATION ---\n",
    "CATALOG_NAME = \"spotify_etl\"\n",
    "SILVER_SCHEMA = \"silver\"\n",
    "GOLD_SCHEMA = \"gold\"\n",
    "\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG_NAME}.{GOLD_SCHEMA}\")\n",
    "print(f\"Source (Silver): {CATALOG_NAME}.{SILVER_SCHEMA}\")\n",
    "print(f\"Destination (Gold): {CATALOG_NAME}.{GOLD_SCHEMA}\")\n",
    "\n",
    "# --- 2. LOAD SILVER TABLES ---\n",
    "fct_plays = spark.table(f\"{CATALOG_NAME}.{SILVER_SCHEMA}.fct_plays\")\n",
    "dim_tracks = spark.table(f\"{CATALOG_NAME}.{SILVER_SCHEMA}.dim_tracks\")\n",
    "dim_artists = spark.table(f\"{CATALOG_NAME}.{SILVER_SCHEMA}.dim_artists\")\n",
    "dim_time = spark.table(f\"{CATALOG_NAME}.{SILVER_SCHEMA}.dim_time\")\n",
    "\n",
    "# --- 3. CREATE BASE ANALYTICS VIEW (JOIN) ---\n",
    "# This view combines the silver tables to facilitate aggregations\n",
    "base_analytics_df = fct_plays \\\n",
    "    .join(dim_tracks, \"track_id\", \"left\") \\\n",
    "    .join(dim_artists, fct_plays.artist_id == dim_artists.artist_id, \"left\") \\\n",
    "    .join(dim_time, \"play_timestamp\", \"left\") \\\n",
    "    .select(\n",
    "        fct_plays.play_id,\n",
    "        fct_plays.play_timestamp,\n",
    "        fct_plays.duration_ms,\n",
    "        fct_plays.context_type,\n",
    "        dim_tracks.track_id,\n",
    "        dim_tracks.track_name,\n",
    "        dim_tracks.popularity,\n",
    "        dim_artists.artist_id,\n",
    "        dim_artists.artist_name,\n",
    "        dim_artists.genres,\n",
    "        dim_time.hour_of_day,\n",
    "        dim_time.weekday_name,\n",
    "        date_format(fct_plays.play_timestamp, \"yyyy-MM\").alias(\"month\")\n",
    "    )\n",
    "\n",
    "# Cache for performance and create a Temp View\n",
    "base_analytics_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{CATALOG_NAME}.{GOLD_SCHEMA}.base_analytics\")\n",
    "print(\"The analytics view 'v_base_analytics' has been created and cached.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff88789a-8e13-41ea-bbaa-31da10e7c5f2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "gold_user_listening_summary_tabel"
    }
   },
   "outputs": [],
   "source": [
    "# Since the API does not provide a distinct user ID, we will aggregate everything\n",
    "# for a single user, \"default_user\".\n",
    "\n",
    "print(\"Creating gold.gold_user_listening_summary...\")\n",
    "\n",
    "# Use Spark SQL on our view\n",
    "gold_user_summary = spark.sql(\"\"\"\n",
    "    WITH user_summary AS (\n",
    "        SELECT\n",
    "            'default_user' AS user_id,\n",
    "            COUNT(play_id) AS total_tracks,\n",
    "            COUNT(DISTINCT artist_id) AS unique_artists,\n",
    "            SUM(duration_ms / 60000.0) AS total_minutes\n",
    "        FROM {CATALOG_NAME}.{GOLD_SCHEMA}.base_analytics\n",
    "    ),\n",
    "    top_artist AS (\n",
    "        SELECT\n",
    "            artist_name AS favorite_artist,\n",
    "            COUNT(*) AS plays\n",
    "        FROM v_base_analytics\n",
    "        GROUP BY artist_name\n",
    "        ORDER BY plays DESC\n",
    "        LIMIT 1\n",
    "    ),\n",
    "    top_track AS (\n",
    "        SELECT\n",
    "            track_name AS top_track,\n",
    "            COUNT(*) AS plays\n",
    "        FROM v_base_analytics\n",
    "        GROUP BY track_name\n",
    "        ORDER BY plays DESC\n",
    "        LIMIT 1\n",
    "    )\n",
    "    SELECT\n",
    "        us.user_id,\n",
    "        us.total_tracks,\n",
    "        us.unique_artists,\n",
    "        us.total_minutes,\n",
    "        ta.favorite_artist,\n",
    "        tt.top_track\n",
    "    FROM user_summary us\n",
    "    CROSS JOIN top_artist ta\n",
    "    CROSS JOIN top_track tt\n",
    "\"\"\")\n",
    "\n",
    "gold_user_summary.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{CATALOG_NAME}.{GOLD_SCHEMA}.gold_user_listening_summary\")\n",
    "    \n",
    "print(f\"Table {CATALOG_NAME}.{GOLD_SCHEMA}.gold_user_listening_summary has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46026707-6b55-4e60-9ae0-400f26d0f37c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "gold_top_tracks_tabel"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Creating gold.gold_top_tracks...\")\n",
    "\n",
    "gold_top_tracks = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        track_id,\n",
    "        track_name,\n",
    "        artist_name,\n",
    "        COUNT(play_id) AS play_count,\n",
    "        SUM(duration_ms / 60000.0) AS total_minutes,\n",
    "        MAX(popularity) AS popularity\n",
    "    FROM v_base_analytics\n",
    "    WHERE track_id IS NOT NULL\n",
    "    GROUP BY track_id, track_name, artist_name\n",
    "    ORDER BY play_count DESC\n",
    "\"\"\")\n",
    "\n",
    "gold_top_tracks.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{CATALOG_NAME}.{GOLD_SCHEMA}.gold_top_tracks\")\n",
    "\n",
    "print(f\"Table {CATALOG_NAME}.{GOLD_SCHEMA}.gold_top_tracks has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f4c2b88-f221-457d-90af-260a16b41eb8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "gold_top_artists_tabel"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Creating gold.gold_top_artists...\")\n",
    "\n",
    "gold_top_artists = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        artist_id,\n",
    "        artist_name,\n",
    "        COUNT(play_id) AS total_plays,\n",
    "        COUNT(DISTINCT track_id) AS unique_tracks,\n",
    "        SUM(duration_ms / 60000.0) AS total_minutes,\n",
    "        FIRST(genres) as genres -- Retrieve genres\n",
    "    FROM v_base_analytics\n",
    "    WHERE artist_id IS NOT NULL\n",
    "    GROUP BY artist_id, artist_name\n",
    "    ORDER BY total_plays DESC\n",
    "\"\"\")\n",
    "\n",
    "gold_top_artists.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{CATALOG_NAME}.{GOLD_SCHEMA}.gold_top_artists\")\n",
    "    \n",
    "print(f\"Table {CATALOG_NAME}.{GOLD_SCHEMA}.gold_top_artists has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a853529f-bce4-4ec9-bddd-f188dc8a0506",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "gold_genre_trends_tabel"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Creating gold.gold_genre_trends...\")\n",
    "\n",
    "# Here we use \"explode\" to transform the genres array into separate rows\n",
    "gold_genre_trends = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        genre,\n",
    "        month,\n",
    "        COUNT(play_id) AS total_plays,\n",
    "        AVG(popularity) AS avg_popularity,\n",
    "        COUNT(DISTINCT 'default_user') AS unique_users -- Hardcoded\n",
    "    FROM v_base_analytics\n",
    "    LATERAL VIEW explode(genres) exploded_genres AS genre\n",
    "    WHERE genre IS NOT NULL\n",
    "    GROUP BY genre, month\n",
    "    ORDER BY month, total_plays DESC\n",
    "\"\"\")\n",
    "\n",
    "gold_genre_trends.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{CATALOG_NAME}.{GOLD_SCHEMA}.gold_genre_trends\")\n",
    "    \n",
    "print(f\"Table {CATALOG_NAME}.{GOLD_SCHEMA}.gold_genre_trends has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9718574f-afb8-4184-9ea6-65fa4d949ac0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "gold_listening_patterns_tabel"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Creating gold.gold_listening_patterns...\")\n",
    "\n",
    "gold_listening_patterns = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        'default_user' as user_id,\n",
    "        hour_of_day,\n",
    "        weekday_name,\n",
    "        SUM(duration_ms / 60000.0) AS total_minutes\n",
    "        -- avg_session_length is complex and requires log analysis, omitted for now\n",
    "        -- most_common_device is unavailable from the API\n",
    "    FROM v_base_analytics\n",
    "    GROUP BY user_id, hour_of_day, weekday_name\n",
    "    ORDER BY hour_of_day, weekday_name\n",
    "\"\"\")\n",
    "\n",
    "gold_listening_patterns.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{CATALOG_NAME}.{GOLD_SCHEMA}.gold_listening_patterns\")\n",
    "    \n",
    "print(f\"Table {CATALOG_NAME}.{GOLD_SCHEMA}.gold_listening_patterns has been created.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_gold_aggregation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
